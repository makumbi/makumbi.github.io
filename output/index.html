<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
    <title>Alex Makumbi</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="This space is designed for software developers, technology enthusiast and open minded individuals unafraid to question everything">
    <meta name="author" content="Alex Makumbi">
    <meta name="keywords" content="Software Developer, Technology, Blog, Personal Development, Tutorials, 
                Systems engineering, systems security engineering, assurance, trustworthiness, 
                information security, information security policy, security architecture, security design, 
                system life cycle, verification, validation, disposal, integration, implementation, stakeholder, 
                security requirements, protection needs, resiliency, requirements analysis, risk management, 
                risk assessment, risk treatment, security authorization, engineering trades, systems, 
                system-of-systems, system element, system component, penetration testing, inspection, review, 
                developmental engineering, field engineering, specifications">
    <meta name="generator" content="JBake">

    <!-- Le styles -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/asciidoctor.css" rel="stylesheet">
    <link href="css/base.css" rel="stylesheet">
    <link href="css/prettify.css" rel="stylesheet">

    <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="js/html5shiv.min.js"></script>
    <![endif]-->

    <!-- Fav and touch icons -->
    <!--<link rel="apple-touch-icon-precomposed" sizes="144x144" href="../assets/ico/apple-touch-icon-144-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="114x114" href="../assets/ico/apple-touch-icon-114-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="72x72" href="../assets/ico/apple-touch-icon-72-precomposed.png">
    <link rel="apple-touch-icon-precomposed" href="../assets/ico/apple-touch-icon-57-precomposed.png">-->
    <link rel="shortcut icon" href="favicon.ico">
  </head>
  <body onload="prettyPrint()">
    <div id="wrap">
	
	<!-- Fixed navbar -->
    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
        <a class="navbar-brand" href="https://makumbi.github.io/">makumbi
          </a>
        </div>
        <div class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            <li><a href="index.html">Home</a></li>
            <li><a href="about.html">About</a></li>           
            <li><a href="archive.html">Archive</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </div>
    <div class="container">

	<div class="page-header">
		<h1>Articles</h1>
	</div>
        
  			<a href="blog/2017/incident-management-patch-management.html"><h1>Incident Management and Patch Management</h1></a>
  			<p>08 March 2017</p>
  			<p><p>Building a secure software product by going through the Software Development Life-Cycle (SDLC) processes (requirements, design, develop, test and deploy) following best practices, one can assume that the product can be built robust enough needing minimum attention once it is in service. As we’ve learned in this course, that reality does not exist for public actively used software products; even for privately used software products for that matter. Steps have to be taken early in the SDLC to address worse case scenarios such beaches into the product, vulnerabilities found in code etc. </p>
<p>Incident management and patch management plans developed early in the SDLC of a software product aim to establish controls to ensure damage to the product is mitigated or is restored as quickly as possible. Incident management outlines policy guidelines that an incident team must follow which can include for example the duration a software product can be offline (depending on the tolerance level of the organization), how incidents are archived, a team of incident responders is identified, trained and provided necessary tools etc. These guidelines are well documented early in the SDLC before the product goes live.</p>
<p>Patch management carefully outlines policy guidelines on how to approach software patches keeping in mind the time it would take to make patches, how much it would cost to make patches and time and cost of testing. Policies clearly communicate to software engineers what type of patches to prioritize and which tools to use in addressing various patches.</p>
<p>Incident and Patch management are necessary activities that ensure that once the software product is deployed, controls are in place to identify, protect, detect, respond and recover a software product from a breach or vulnerability. </p>
<p><strong>Sources</strong></p>
<p>National Institute of Standards and Technology. (2014). Framework for Improving Critical Infrastructure Cybersecurity. Retrieved from <a href="https://www.nist.gov/sites/default/files/documents/cyberframework/cybersecurity-framework-021214.pdf">https://www.nist.gov/sites/default/files/documents/cyberframework/cybersecurity-framework-021214.pdf</a></p></p>
  			<a href="blog/2017/incident-management-response.html"><h1>Incident Management Response</h1></a>
  			<p>04 March 2017</p>
  			<p><h3>Scenario of a breach</h3>
<p>One day, large sums of money were withdrawn from several networked ATM systems by the same User ID.</p>
<h3>Incident Management</h3>
<p>A large sums of money was withdrawn from several networked ATM systems by the same User ID. Given that the core existence of a bank is to manage and keep customers money safe and secure, we have to identify this incident as a major incident (high urgency) because of its impact to customers and integrity of the bank’s reputation in community. There is a lot of unknowns in regards to the extent of the breach. We need to know how the attacker managed to exploit our current defenses, does the attacker have access to private and confidential information of a significant number of individuals, how quickly can we restore the ATM system among other questions to be asked.</p>
<p>Once the breach has been made aware to the incident manager, he summons the 1st level support to conduct an immediate incident resolution. Their objective is to use any means possible to stop the damage and restore the ATM system back to its original state. In our case, they would have to patch up the vulnerability that allowed the attacker to exploit the system causing the breach. Since this breach is of high urgency the time allocated to resolve the breach is 1 hour, and if that time exceeds the incident has to be transferred to team within 2nd level support. If hypothetically my role was incident manager, I would immediately bring the issue to 2nd level support to mitigate the time it takes to resolve the security breach instead of summoning the 1st level support because of the urgency of the breach. </p>
<h3>Incident Response Processes</h3>
<p>The 1st level and 2nd level management of incident response requires response teams to recover and gather as much information about the breach to be recorded and stored for archiving. A collection of incident investigations is archived for future reference to ensure that swift action is taken on recurring breaches or service interruptions in the future. It is important to also note that when an incident is logged, the duration and how the incident was resolved is also recorded. Incident logging is also helpful to gain an insight as to the kinds of breaches or service interruptions the organization experiences overtime (ITIL Incident Management, 2016). </p>
<p>As mentioned before, if hypothetically I was an incident manager I would have immediately summoned 2nd level support team. The 2nd level support team would quickly look at archived incident reports to determine if a previous incident or detected vulnerability exploit on the ATM system is similar to our current breach. If the detected vulnerability was not previously archived, the ATM system networked breach would be a “Zero Day Attack”. These attacks are difficult to get to a root cause because they are new to the system. Specialist support groups or third party experts have to be involved to see that no farther withdrawal of money is made from the ATM system.</p>
<p>When an accurate analysis of the breach is gathered, bank users and staff members would be made aware of the occurring or occurred incident in an effort to get users vigilant and keep an eye out for suspicious activities or to anticipate any service interruptions. The security incident notification message to ATM system users will have instructions with step by step explanations on actions they can take to protect themselves.</p>
<h4>Instructions:</h4>
<ol>
  <li>Do not use ATM system for 48hrs until further notice</li>
  <li>Change ATM pin number</li>
  <li>Call customer service on suspicious account transactions</li>
</ol>
<h3>Incident follow-up and additional processes</h3>
<p>During the incident management processes, detailed data about the breach was thoroughly documented to be archived. Details such as how the attacker managed to break the ATM system defenses, how much damage was caused to the bank and ATM users, how long it took to restore the ATM system, which response teams addressed the breach, how much money did it cost the bank, what tools where used to mitigate further withdrawal of money. Before the case is fully closed, a final review is conducted to ensure the incident is actually resolved and that sufficient detail supporting the incident is of quality. </p>
<p>Once the case has gone through quality control and properly archived, an ongoing monitoring process of the system for prior incidents including the ATM system networked breach has to be evaluated to continue implementing counter-measures that address likely weaknesses to the system.</p>
<p><strong>Sources</strong> </p>
<p>ITIL Incident Management. (2016). Incident Management. Retrieved from <a href="http://wiki.en.it-processmaps.com/index.php/Incident_Management#Incident-Record">http://wiki.en.it-processmaps.com/index.php/Incident_Management#Incident-Record</a> </p>
<p>National Institute of Standards and Technology. (2014). Framework for Improving Critical Infrastructure Cybersecurity. Retrieved from <a href="https://www.nist.gov/sites/default/files/documents/cyberframework/cybersecurity-framework-021214.pdf">https://www.nist.gov/sites/default/files/documents/cyberframework/cybersecurity-framework-021214.pdf</a></p></p>
  			<a href="blog/2017/black-box-and-white-box-testing.html"><h1>Sensitive Data Exposer: Black Box and White Box Test Cases</h1></a>
  			<p>26 February 2017</p>
  			<p><p><strong>Note:</strong> ATM Use Cases diagram can be viewed on the following link <a href="http://www.math-cs.gordon.edu/courses/cs211/ATMExample/UseCases.html" title="ATM Use Cases">ATM Example Use Case</a></p>
<p>The ATM is designed in a way that once a user has successfully inserted a valid bank card and enters a valid four-digit pin, they are presented with four transaction options: withdrawal, deposit, transfer, and account inquiry. While the user navigates the ATM system, one threat that could pose as a danger to personal identifiable information (PII) is sensitive data exposer. This article is going to focus on the transaction feature/function of the ATM design because this is where the vulnerability is likely to occur.</p>
<h4>Is threat mitigated by the current design?</h4>
<p>It is difficult to determine whether the current design of ATM system mitigates sensitive data exposure because it does not explicitly outline how it addresses or if it recognizes the threat. The assumption will be that the current design does not recognize the sensitive data exposure as a threat. Before we come to a conclusion, we will conduct a black box test to understand how the design reacts to various tests. A high-level design of the ATM system will be used as the basis for tests. The high-level design recognized the threat sensitive data exposure had on PII and took steps to mitigate the vulnerability. These steps included limiting the amount of information displayed on the screen and using generic messages when a transaction is not successful.</p>
<h3>User withdrawals</h3>
<p>Each time a user wants to withdrawal N amount, the bank system internally determines whether they can or cannot withdrawal N amount by checking bank account records of the user. A message output depends on whether the user can or cannot withdrawal. If the user can withdrawal N amount, they are prompted to confirm that N amount is to be withdrawn. On the other hand, if the user does not have sufficient funds and cannot withdrawal, they are notified that no withdrawal can be made at that time.</p>
<h3>User inquiring</h3>
<p>When a user requests an inquiry to their account, the bank internally checks the user’s account summary of checking account and savings account. The user is then provided the option of printing out summary on a receipt.</p>
<h3>User transferring</h3>
<p>Each time a user wants to transfer N amount, internally the bank system determines whether they can or cannot transfer N amount by checking bank account records of the user. A message output depends on whether the user can or cannot transfer. If the user can transfer N amount, they are prompted to confirm that N amount is to be transferred. On the other hand, if the user does not have sufficient funds in the given account, they are notified that transfer cannot be made at that time.</p>
<h3>User depositing</h3>
<p>Once the user indicates that they want to deposit N amount in account, the ATM system prompts the user to specify which account they want to deposit the amount. The user cannot deposit more than $25,000 in either account. The bank internally updates its records once it has determined that indeed the amount deposited is correct.</p>
<h2>Test steps</h2>
<ol>
  <li>Total amount in checking account.</li>
  <li>Total amount in saving account.</li>
  <li>Transfer N amount from checking account to saving account.</li>
  <li>Transfer N amount from saving account to checking account.</li>
  <li>Deposit N amount in checking account.</li>
  <li>Deposit N amount in savings account.</li>
  <li>Withdrawal N &gt; $1,000 from checking account.</li>
  <li>Withdrawal N &lt; $10 from savings account.</li>
</ol>
<h3>Test tools that would employ to perform testing</h3>
<p>The tools that I would employ to test sensitive data exposure vulnerability on ATM system would be Katalon Studio and Hp Fortify on Demand. Katalon Studio has the capability of conducting automated tests as well as manual test with the UI layer of an application.</p>
<p>Hp Fortify on Demand provides security as a service and manages security risk. Fortify on demand also has the capabilities of conducting automated tests with a full audit of results. Fortify differs from Katalon Studio because it focuses more on security as a posed to the overall functionality of an application (Fortify on Demand, 2017).</p></p>
  			<a href="blog/2017/tools-to-enforce-secure-code.html"><h1>Tools for Enforcing Secure Code</h1></a>
  			<p>19 February 2017</p>
  			<p><p>A simple Google search for an open source static code analysis tool displays a variety of tools for secure code analysis. Analyzing the various tools in the results menu, you quickly realize two things; one, that there are many open source code analysis tools, and two, the range at which code analysis tools differ from one another. Generally speaking, tools encountered during the survey some were multi-language (ex: VisualCodeGrepper, Zed Attack Proxy, PMD, and YASCA) others were language specific, for instance, only focusing on JAVA (ex: OWASP LAPSE+, FindBugs), PHP (ex: RIPS, and DevBug), or C++ (ex: Flawfinder, and CPPCheck). Another quick distinction between tools is the capabilities they had to conduct analysis. Analysis tools could either do both static and dynamic code analysis, others could only perform either static or dynamic code analysis. Furthermore, within language specific code analysis tools, tools differed further in the types of vulnerabilities they detected.</p>
<p>Recognizing the distinction and differences between open source secure code analysis tools is important and should not be overlook. A series of discussions among programmers and security team needs to take place in deciding a particular code analysis tool(s). Questions to be asked are; Does the tool support language(s) on the project? What type of vulnerability and code issues to they need to look for in code? What’s the rate of false positives associated with the tool(s)? among other targeted questions.</p>
<h4>Selected open source tool</h4>
<p>FindBugs code analysis tool will be used to demonstrate my understanding and purpose of open source code analysis tools. FindBugs is an open source code analyzer that focuses on detecting possible bugs in Java programs. Since the tool is written in Java, it is a stand-alone GUI application so it can be used on many platforms. Finally, FindBugs records potential errors in four ranks; scariest, scary, troubling and of concern (Markus, 2012).</p>
<h4>Summary tool strengths and weaknesses</h4>
<p><strong>Strengths</strong></p>
<p>Personally I prefer open source code analysis tools that focus only on a particular language because it allows the tool designer(s) to not only worry about detecting low hanging fruits, but get deeper into higher level coding vulnerabilities. Findbugs has a very low number of false positives. So the tool is generally reliable and finds valid bugs. The option of turning off scanning for certain types of bugs to be a useful feature which would increase the convenience of using FindBugs in different situations.</p>
<p><strong>Weakness</strong></p>
<p>FindBugs is not very customizable. For instance, Findbugs has its own defined coding style (naming conventions of methods etc.). There should be a way to customize the coding style so that it can analyze the code against a custom coding style specified by the user. It will not always be the case that the user will be coding in the style defined in FindBugs (Sandcastle, 2009).</p>
<h3>Source code for analysis</h3>
<pre><code>   private static void createConnection()
    {
        try
        {
            Class.forName(&quot;org.apache.derby.jdbc.ClientDriver&quot;).newInstance();
            //Get a connection
            conn = DriverManager.getConnection(dbURL); 
            
        }
        catch (ClassNotFoundException | InstantiationException | IllegalAccessException | SQLException except)
        {
            except.printStackTrace();
        }
        
    }
    
    private static void insertUserInfor(String userName, String userPass)
    {
        try
        {
            createConnection();
            stmt = conn.createStatement();
            stmt.execute(&quot;insert into &quot; + tableName + &quot; values (&#39;&quot; +
                    userName + &quot;&#39;, &#39;&quot; + userPass + &quot;&#39;)&quot;);
            
            stmt.close();
        }
        catch (SQLException sqlExcept)
        {
            sqlExcept.printStackTrace();
        }
    }
</code></pre>
<h4>Results after applying FindBugs to the code</h4>
<p>Netbeans makes it easy to apply Findbugs on Java code. The tool is deployed as follows; simply navigate to the navigation bar and click on sources, then click on inspect and select Findbugs. On the Java code that was inspected, Findbugs quickly detected troubling bugs within the code and displayed them on the results console. In random order, the tool grouped bugs in two categories; security and bad practice. On the left hand side of the results console, Netbeans has a feature that allows a user to rank bugs, so in my case, after clicking on the feature security category is placed at the top and bad practice category is placed below.</p>
<p>Under security category, Findbugs detected that the Java code is vulnerable to SQL injection. The tool was able to trace through the folder tree locating the precise method the vulnerability was occurring in the code. Findbugs gives a recommendation to mitigate the bug: “Consider using a prepared statement instead. It is more efficient and less vulnerable to SQL injection attacks”.</p>
<p>Under bad practice category, Findbugs detected one vulnerability at two locations in the code. The vulnerability detected was improper closing of a database resource. Findbugs’ recommendation to mitigate the bug: “Failure to close database resources on all paths out of a method may result in poor performance, and could cause the application to have problems communicating with the database”.</p>
<p><strong>Sources</strong></p>
<p>CyberSecology. “The OWASP Zed Attack Proxy (ZAP) Scanner” CyberSecology-Web Scanner Reviews. Retrieved from <a href="http://cybersecology.com/the-owasp-zed-attack-proxy-zap-scanner/">http://cybersecology.com/the-owasp-zed-attack-proxy-zap-scanner/</a> (On 17 February 2017).</p>
<p>InfoSec Institute. (2013). “Which Weapon Should I Choose for Web Penetration Testing? 3.0” Retrieved from <a href="http://resources.infosecinstitute.com/which-weapon-should-i-choose-for-web-penetration-testing-3-0/#gref">http://resources.infosecinstitute.com/which-weapon-should-i-choose-for-web-penetration-testing-3-0/#gref</a> (On 17 February 2017).</p>
<p>Markus, Sprunck. (2012)."Findbugs – Static Code Analysis of Java" Methods and Tools. Retrieved from <a href="http://www.methodsandtools.com/tools/findbugs.php">http://www.methodsandtools.com/tools/findbugs.php</a> (On 18 February 2017).</p>
<p>Sandcastle. (2009). “An Evaluation of FindBugs” Analysis of Software Artifacts. Retrieved from <a href="http://www.cs.cmu.edu/~aldrich/courses/654/tools/Sandcastle-FindBugs-2009.pdf">http://www.cs.cmu.edu/~aldrich/courses/654/tools/Sandcastle-FindBugs-2009.pdf</a> (On 18 February 2017).</p></p>
  			<a href="blog/2017/threat-modeling.html"><h1>Threat Modeling</h1></a>
  			<p>12 February 2017</p>
  			<p><p>Building on the previous assignment where we discussed misuse/abuse case using ATM machine as an example, this week we discuss the threat modeling process. Threat modeling ranks threats during software design identifying which assets or components are most critical to the business and ranks them according to damage a threat would cause to the business. This ranking helps teams prioritize energy and resources on high ranking assets during a breach in an effort to mitigate damage. As a result, security code review of components whose threat modeling has ranked with high risk threat is prioritized.</p>
<p>Threat modeling process encompasses three high level steps which are decompose the application, determine and rank threats, and determine countermeasures and mitigation. This paper is going to delve deep into each step to get a better understanding how threat modeling is implemented.</p>
<p><strong>Decompose the Application</strong></p>
<blockquote>
  <blockquote>
    <p>As the first step in threat modeling process, attention is focused on gaining an understanding of the application and how it interacts with external entities. What does this mean? It means identifying entry points an attacker can use to exploited the application, identify trust levels as it pertains to access levels among others.</p>
  </blockquote>
</blockquote>
<p><strong>Determine and rank threats</strong></p>
<blockquote>
  <blockquote>
    <p>It is not hard to guess what this step is all about. Threats are determined and ranked using a threat categorization methodology. OWASP outlines a threat categorization known as STRIDE, which we will be using to rank threats to the ATM machine. STRIDE stands for – Spoofing, Tampering, Repudiation, Information disclosure, Denial of service, and Elevation of privilege.</p>
  </blockquote>
</blockquote>
<p><strong>Determine countermeasures and mitigation</strong></p>
<blockquote>
  <blockquote>
    <p>Once a risk ranking is assigned to the threats, it is possible to sort threats from the highest to the lowest risk, and prioritize the mitigation effort, such as by responding to such threats by applying the identified countermeasures.</p>
  </blockquote>
</blockquote>
<h4>External Dependences</h4>
<p>We also outline external dependences. External dependences are items external to the code of the application that may pose a threat to the application (OWASP, 2015). For our ATM machine, an external dependency would be the machine’s connection to the bank both internally and physically.</p>
<h4>Entry Points</h4>
<p>Entry points are essentially an application’s attack surface. Meaning that we define the interfaces which potential attackers can interact with the application or supply it with data. For our ATM machine, the entry points are the pin pad, credit card reader, bank and operator.</p>
<h4>Assets</h4>
<p>Threat models are created during the design of an application to outline threat targets. Threat targets are things that attackers are interested in, this can be items/areas of interest. Assets are the reason threats will exists. Assets can be both physical and abstract. For our ATM machine, an abstract asset might be degrading people’s trust in using ATM machines. A physical asset might be a list of account records and personal information, as well as the actual stealing of money.</p>
<h4>Ranking of Threats</h4>
<p>Threats are ranked according to potential risk factors. Risk factors are determined by the impact they pose to a business and component and ranked in a list of high, medium, low risk. DREAD is a Microsoft threat-risk ranking model that we will use to rank threat factors. The risk factorization of the model allows the use of values influencing factors of a threat. Questions that threat-risk ranking model aims to answer are:<br/>- For Damage: How big would the damage be if the attack succeeded?<br/>- For Reproducibility: How easy is it to reproduce an attack to work?<br/>- For Exploitability: How much time, effort, and expertise is needed to exploit the threat?<br/>- For Affected Users: If a threat were exploited, what percentage of users would be affected?<br/>- For Discoverability: How easy is it for an attacker to discover this threat?</p>
<h3>Mitigation for threats.</h3>
<p>Once the ATM has detected the inserted bank card is valid, the customer is prompted to enter a four-digit pin. This user authentication is threatened by <strong>brute force authentication</strong> and <strong>dictionary attacks</strong>. To mitigate these threats, the ATM should lock account after N failed login attempts as well as validate the minimum length and complexity of pin. It is important that when user enters wrong pin a generic error message is shown to ensure that an attacker is not provided clues as to which user account is stored in the bank. All these implemented measures collectively in return mitigate <strong>broken authentication</strong> and <strong>session management</strong>.</p>
<p>In order to mitigate the threat of <strong>sensitive data exposure</strong>, it is critical that the ATM displays the minimum number of information for each transaction. To give an example, let’s say a customer wants to withdrawal N amount from checking account. If N amount is more than amount in checking account, the ATM system should display a generic message ensuring PII is protected. To take it further, for each transaction, whether it is withdrawal, deposit, transfer, or inquiry, the customer needs to be prompted with a message asking for a confirmation to carry out an action.</p>
<p><strong>Sources</strong></p>
<p>Bjork C. Russell. ATM Simulation. Retrieved from <a href="http://www.math-cs.gordon.edu/courses/cs211/ATMExample/UseCases.html">http://www.math-cs.gordon.edu/courses/cs211/ATMExample/UseCases.html</a></p>
<p>OWASP. (2015). Application Threat Modeling. Creative Commons 3.0 License. Retrieved from <a href="https://www.owasp.org/index.php/Application_Threat_Modeling#STRIDE">https://www.owasp.org/index.php/Application_Threat_Modeling#STRIDE</a></p></p>
  			<a href="blog/2017/secure-software-design.html"><h1>Secure Software Design</h1></a>
  			<p>05 February 2017</p>
  			<p><h2>Least privilege</h2>
<p>Architecture and Design Considerations for Secure Software by Software Assurance says that least privilege is a principle that each component, including components from the outside world and components embedded into the program, and every user of the system, use the least set of privilege necessary to accomplish desired tasks and objectives. The objective of employing least privilege principle is to reduce the number of actors (components and users) in the system who are granted high levels of privilege, and the duration of time each actor can hold onto those privileges.</p>
<h4>Benefits</h4>
<p>A benefit for employing the least privilege principle manifests in the way project stake holders (programmers, system administers etc..) look at security measures. The military has a saying’ - “need to know bases”. Those few words encapsulate the framework of which stake holders view the project and at the core of how they handle decisions. The unintentional, unwanted, or improper use of privileges are less likely to take place since the minimum amount of privileges are granted to users and components (Langford Jeff, 2003). </p>
<p>A benefit which does not come much as a surprise is that it is fundamentally and practically harder to reduce access privileges for actors when each actor is given a maximum amount of privileges at the beginning, than it when actors are given the least amount of privileges. </p>
<h4>Example</h4>
<p>Last week we discussed requirements misuse/abuse cases and used an ATM machine as an example. This week I will use the ATM machine again to explain how least privilege principle is employed and the reasons for using the principle. An ATM is made to be simple. Customers are allowed access to deposit, withdrawal, transfer, and inquiry. Customers cannot communicate with their respective bank edit their profiles, edit bank pin, change username, edit account and routing number. Employing this principle limits the damage that can result from an accident or error.</p>
<h2>Don’t expose vulnerable or high-consequence components</h2>
<p>When you host a large gathering at your home chances are that you will not leave a large ward of cash laying in the sitting room, or your passport visa along with your social security number on the kitchen table. These are high-consequence items that are being exposed to a large group of not very well unknown people. In software development a program usually hosts sensitive business data, personal identifiable information (PII), sensitive program executables and functions. These high consequence components should not be exposed to non-consequence components, meaning that high-consequence components should be stored separately from non-consequence components. The passport visa, social security number, and the large ward of cash should be placed in a boxed safe stored in a low traffic area such a locked bedroom. </p>
<h4>Benefits and Examples</h4>
<p>Not exposing vulnerable or high-consequence components means that you are actively and deliberately isolating trusted entities from untrusted entities. For example, program data executables and configuration data would be stored in a different location with the assumption that environment data is not trustworthy. This deliberate isolation of trusted entities from untrusted entities naturally reduces the attack surface and here is why. Going back to our house analogy, the act of removing passport visa and social security number along with the large ward of cash from the kitchen to a safe box in a locked bedroom drastically reduces the attack surface to one point of entry. It is easier to keep a recorded log of activities in a bedroom compared to an open concept kitchen. As a result, the attacker has a harder time locating and gaining access on vulnerable or high-consequence components because the attacker is left guessing where vulnerable/high-consequence components could be held his given limited resources to operate.</p>
<h2>Complete mediation</h2>
<p>Complete mediation design principle is a mechanism of which a software system systematically checks required access an object has each time that object attempts to access any type of resource. A reference monitor is a piece of software that checks every reference made by subjects to objects (Implementing Complete Mediation, by Schneider). To find out why reference monitor is critical for complete mediation, we use a simple example, if the access control rights of a subject are decreased after the first time rights are granted and the system does not check the next access to that object, security vulnerabilities can occur throughout the system.</p>
<p><strong>Note:</strong> When we say object, it can mean the various components that encompass the whole system (including sub-components), outside plugins or software, users etc.</p>
<h4>Benefits</h4>
<p>Software Assurance (SwA) Pocket Guide Resources in an article titled Architecture and Design Considerations for Secure Software stated it accurately writing that complete mediation is the “primary underpinning of the protection system” (Software Assurance, 2008). The consistent evaluation of subject’s access to objects not only ensures that no permission violations can occur, but also makes it easier to log successful and unsuccessful authentication attempts on resources. A benefit would then be that during a security breach, swift actions can be taken to mitigate damage since access to various components is accurately logged. </p>
<h4>Example</h4>
<p>This past fall 16’ I was a Software Developer Intern for a startup creating batteries for electric vehicles. My role as a back-end developer exposed me to Amazon Web Services (AWS) cloud ecosystem. AWS employs complete mediation. In AWS ecosystem each user, AWS tool, and outside plugins are given various levels of access. The AWS administrator controls the amount of access each entity possesses. To give an example, for the Lambda Function to filter data coming from our API Gateway and then store the appropriate data in DynamoDB, the Lambda Function had to get appropriate permission from DynamoDB by triggering the two together. In order for the API Gateway to send raw data in Lambda Function, Lambda Function and API Gateway both had to be triggered together with the appropriate access. Lastly, the API Gateway had to establish appropriate access level with an outside entity where the data would be generated which in our case was customer purchase orders using a third party platform. Any change in access level along the chain causes the entire system to break. </p>
<h2>Psychological acceptability</h2>
<p>Psychological acceptability design principle is another way of saying software system design should be intuitive to any user, particularly the client side. In my view, to achieve an easy to understand or intuitive user interface (UX), the design should also follow established guidelines for supporting accessibility of disabled people. There are more than one billion people with various disabilities all around the world, of whom approximately 285 million are visually-impaired and 360 million hearing impaired (Rezaei A. Yashar, Heisenberg Gernot, and Heiden Wolfgang, 2014). With this approach, impaired users not only are able to easily apply protection mechanisms correctly, regular users are able to do so as well, increasing the security of the system. </p>
<h4>Benefit</h4>
<p>The overarching benefit that derives from employing psychological acceptability design principle is the drastic reduction of mistakes on the part of the user. The reduction of mistakes in tern translate to a more robust secure system.</p>
<h4>Examples</h4>
<p>The user must become involved in security decisions at some point. Either when the system is loading or when the system attempts a privileged operation. To use an everyday example, today it seems every company is using an interactive map for something. In order for an application to retrieve a user’s geolocation, by law the application has to prompt the user for access. Another example is whenever a user installs an application from an outside source, they are to be prompted for access of resources to be used and how they are to be used. </p>
<h2>Minimize the number of high-consequence</h2>
<p>The design principle of minimizing the number of high-consequence components from security risk employs the least privilege principle, separation of privilege, duties, and roles and separation of domains. The key concept of the design principle is to reduce the number of high-consequence components from risk. For example, to separate environments that are not trusted from trusted environments, and reduce the number of entities interacting with the high-consequence components. </p>
<h4>Benefits and Example</h4>
<p>The implementation of least privilege to minimize the number of high-consequence ensures the number of actors in the system that are granted high levels of privilege is reduced strengthening overall security. Another benefit derived from minimize the number of high-consequence is that the separation of domains makes it easier to implement separation of privileges, duties, and duties (Software Assurance Pocket Guide Series).</p>
<p><strong>Sources:</strong></p>
<p>Gegick Michael and Barnum Sean. (2005-2007). Least Privilege. Cigital [PDF file]. Retrieved from <a href="https://www.us-cert.gov/bsi/articles/knowledge/principles/least-privilege">https://www.us-cert.gov/bsi/articles/knowledge/principles/least-privilege</a></p>
<p>Langford Jeff. (2003). Implementing least Privilege at your Enterprise. SANS Institute InfoSec Reading Room [PDF file]. Retrieved from <a href="https://www.sans.org/reading-room/whitepapers/bestprac/implementing-privilege-enterprise-1188">https://www.sans.org/reading-room/whitepapers/bestprac/implementing-privilege-enterprise-1188</a></p>
<p>Mahizharuvi and Alagarsamy. A Security Approach in System Development Life Cycle. Dept of MCA, Computer Center (Vol. 2) [PDF file]. Retrieved from <a href="http://www.ijcta.com/documents/volumes/vol2issue2/ijcta2011020204.pdf">http://www.ijcta.com/documents/volumes/vol2issue2/ijcta2011020204.pdf</a></p>
<p>Micheal C.C, Gegick Michael, and Barnum Sean. (2005-2007). Complete Mediation. Cigital. Retrieved from <a href="https://www.us-cert.gov/bsi/articles/knowledge/principles/complete-mediation">https://www.us-cert.gov/bsi/articles/knowledge/principles/complete-mediation</a> </p>
<p>Rezaei A. Yashar, Heisenberg Gernot, and Heiden Wolfgang. (2014). User Interface Design for Disabled People Under the Influence of Time, Efficiency and Costs. Institute of Visual Computing Bonn-Rhein-Sieg [PDF file]. Retrieved from <a href="https://www.researchgate.net/profile/Gernot_Heisenberg/publication/262601817_User_Interface_Design_for_Disabled_People_Under_the_Influence_of_Time_Efficiency_and_Costs/links/02e7e5384c1486f3ee000000.pdf">https://www.researchgate.net/profile/Gernot_Heisenberg/publication/262601817_User_Interface_Design_for_Disabled_People_Under_the_Influence_of_Time_Efficiency_and_Costs/links/02e7e5384c1486f3ee000000.pdf</a></p>
<p>Software Assurance Pocket Guide Series. 2012. Architecture and Design Considerations for Secure Software. Building Security in Software Assurance (Vol. V) [PDF file]. </p>
<p>Software Assurance. (2008). Enhancing the Development Life Cycle to Produce Secure Software. A Reference Guidebook on Software Assurance (Version 2.0) [PDF file]. Retrieved from <a href="http://www.cis.upenn.edu/~lee/10cis541/papers/DACS-358844.pdf">http://www.cis.upenn.edu/~lee/10cis541/papers/DACS-358844.pdf</a></p>
<p>Schneider B. Fred. Implementing Complete Mediation. Retrieved from <a href="http://www.cs.cornell.edu/courses/cs513/2004SP/NL05.html">http://www.cs.cornell.edu/courses/cs513/2004SP/NL05.html</a> </p></p>
  			<a href="blog/2017/personal-identifiable-information.html"><h1>Personal Identifiable Information (PII)</h1></a>
  			<p>04 February 2017</p>
  			<p><p><img src="/img/re-creditcardform.png" alt="Credit Card Entry Form" /></p>
<p>Personal identifiable information or PII is practically any piece of information about someone maintained by an organization that can be used to distinguish or trace an individual’s identity. Information can include but not limited to name, social security number, date of birth as well as any other information that is linked or linkable to an individual.</p>
<p>PII examples are listed below by no means exhaust possibilities of information that could be considered PII. This is only meant to highlight/provide a framework as of what PII information can encompass. Examples include financial transactions, medical history, criminal history, employment history, individual ‘s name, social security number, passport number, driver‘s license number, credit card number, vehicle registration among others.</p>
<h4>Figure 1</h4>
<p><img src="/img/re-newsupdate.png" alt="News Update form" /></p>
<p>In figure 1, PII data that is being gathered from the form is title, first name, middle name and last name, address, email, and phone number. The purpose for the form is to allow people to subscribe for bi-weekly e-newsletter. This form asks people to enter (optionally) their addresses which is not necessary for a bi-weekly e-newsletter. If I worked for vendor and was tasked to improve security, I would first assess the impact level of storing and maintaining address information. I would conclude that the impact level of storing and maintaining address information is moderate since the expected loss of confidentiality, integrity, or availability could have serious adverse effect on individuals. As a result, I would lean on the side of cation by removing address from the form. </p>
<h4>Figure 2</h4>
<p><img src="/img/re-winmoney.png" alt="Win $10,000,000" /></p>
<p>In figure 2, PII data that is being gathered from the form is name, address and data of birth in order to register to win $10,000,000 dollars. The fact that the form is asking for address is a slight over reach, and here is why, secure software development best practices show that a minimum number of information required to accomplish a particular task is needed - nothing more nothing less. If I worked for the vendor and was tasked to improve security, a possible way I would mitigate this is issue is by removing address from the form and instead wait until the participant has qualified to win the prize to solicit address information if it is needed. </p>
<p><strong>Sources:</strong></p>
<p>Bjork C. Russell. ATM Simulation. Retrieved from <a href="http://www.math-cs.gordon.edu/courses/cs211/ATMExample/Interactions.html#Startup">http://www.math-cs.gordon.edu/courses/cs211/ATMExample/Interactions.html#Startup</a></p>
<p>Erika McCallister, Tim Grance and Karen Scarfone (April 2010). Guide to Protecting the Confidentiality of Personally Identifiable Information (PII). Recommendations of the National Institute of Standards and Technology, NIST Special Publication 800-122.</p>
<p>“Requirements Analysis for Secure Software”. Software Assurance Pocket Guide Series, Development, Volume IV Version21, May 18, 2012.</p></p>
  			<a href="blog/2017/requirements-misuse-and-abuse-cases.html"><h1>Requirements Misuse and Abuse Cases</h1></a>
  			<p>29 January 2017</p>
  			<p><p>We attempt to explain briefly what misuse/abuse cases are and why applying the concept in the development stage of software requirements results in a more robust secure product. Programmers generally create use case diagrams to demonstrate functions, flow and actions that the end-user and the application will perform, this ensures the program functions as it should and meets all the desired requirements. Misuse or abuse cases are similar to use cases, only that with misuse/abuse cases the developer has to place themselves in the shoes of an attacker. The programmer walks through functions, flow and actions of the program with the lenses of an attacker – how will the application or user handle the application in a way that is not intended. Misuse cases provide opportunities to investigate and validate security requirements. </p>
<h3>ATM abuse/misuse cases</h3>
<p><img src="/img/re-atm-system.png" alt="Atm System" /></p>
<p><strong>Note:</strong> The ATM System use cases diagram is displayed above. Use cases diagrams can also be viewed on the following links: </p>
<p><a href="http://www.math-cs.gordon.edu/courses/cs211/ATMExample/UseCases.html" title="ATM Use Cases">ATM Example Use Case</a></p>
<p><a href="http://www.math-cs.gordon.edu/courses/cs211/ATMExample/Interactions.html#Startup" title="Startup Use Case">ATM Operator Startup Use Case</a></p>
<h4>Start-up Use Case</h4>
<p>Before bank customers can begin using the ATM machine, an ATM system operator first has to Start Up the system following this sequence:</p>
<pre><code>1.  Switch on operator panel
2.  Get initial cash in the ATM 
3.  Set initial cash into cash dispenser 
4.  Then open connection to the bank
</code></pre>
<h4>Start-up Misuse/Abuse Case</h4>
<p>The first sequence, operator panel being switched on, does not appear to have contingencies in place that authenticates the operator. As a result, what will most likely happen is <strong>broken authentication</strong> and <strong>session management</strong> allowing a malicious user to compromise the entire system placing customer’s personal identifiable information (PII) in danger. To mitigate this threat, operator panel has to prompt user to enter username and password for user authentication. To mitigate <strong>brute force authentication</strong>, <strong>guess valid user accounts</strong> and <strong>dictionary attacks</strong>, a generic error message is shown when authentication fails as well as locking the system after N failed login attempts. </p>
<p>Lastly, at the moment once the operator set initial cash into cash dispenser a connection to the bank is established. A vulnerability that can occur is <strong>missing function level access control</strong>. This is when a request is not verified, enabling an attacker to forge requests in order to access functionality without proper authorization. To mitigate this vulnerability, operator should be required to enter pin before a connection is established with bank.</p>
<h4>Session Use Case</h4>
<p>After start-up sequence is successful customers are free to begin sessions. Sessions should follow the following sequence:</p>
<pre><code>1.  Valid bank card inserted into ATM
2.  Session is created. Reading card. If card is valid request to enter pin, if card is not valid terminate session.
3.  User enters valid pin 
4.  If pin valid, user can perform following transactions
        a. Withdrawal
        b. Deposit
        c. Transfer
        d. Inquiry
5.  User cancels session (this can be done at any stage of session)
6.  Card ejected
</code></pre>
<h4>Session Misuse/Abuse Case</h4>
<p>Once the ATM has detected the inserted bank card is valid, the customer is prompted to enter a four-digit pin. This user authentication is threatened by <strong>brute force authentication</strong> and <strong>dictionary attacks</strong>. To mitigate these threats, the ATM should lock account after N failed login attempts as well as validate the minimum length and complexity of pin. It is important that when user enters wrong pin a generic error message is shown to ensure that an attacker is not provided clues as to which user account is stored in the bank. All these implemented measures collectively in return mitigate <strong>broken authentication</strong> and <strong>session management</strong>.</p>
<h4>Transaction Use Case</h4>
<p>After a successful pin validation, customer is presented with four transaction options: withdrawal, deposit, transfer, and inquiry. </p>
<h4>Transaction Misuse/Abuse Case</h4>
<p>In order to mitigate the threat of <strong>sensitive data exposer</strong>, it is critical that the ATM displays the minimum number of information for each transaction. To give an example, let’s say a customer wants to withdrawal N amount from checking account. If N amount is more than amount in checking account, the ATM system should display a generic message ensuring PII is protected. To take it further, for each transaction, whether it is withdrawal, deposit, transfer, or inquiry, the customer needs to be prompted with a message asking for a confirmation to carry out an action. This will ensure that <strong>missing function level access control</strong> is mitigated to some extent.</p>
<p><strong>Sources:</strong></p>
<p>OWASP Top Ten Project. Top 10 2013-Top 10. 2002-2013 OWASP Foundation. Retrieved from <a href="https://www.owasp.org/index.php/Top_10_2013-Top_10">https://www.owasp.org/index.php/Top_10_2013-Top_10</a></p></p>
  			<a href="blog/2017/sdlc-training.html"><h1>Software Development Life Cycle (SDLC) Training</h1></a>
  			<p>21 January 2017</p>
  			<p><p>This article allows me to demonstrate the importance of secure training in preparation of software development life-cycles. I will be discussing the importance of security training in preparation for secure software development, providing five reasons for the importance of security training prior to executing the SDL process.</p>
<h4>Meet current and evolving business and compliance needs</h4>
<p>Organizations face new threats each year that aim at causing damage or compromise critical assets or degrade public trust through data dumps among others. The most effective way to keep on par with evolving threats is to prioritize business security training in preparation for secure software development. Security training ensures that as business requirements change, employees are in position to conceptualize and focus on employing secure software development practices and techniques, assuring that critical assets are adequately protected. Hence, through security training, a business requirements approach to developing software is taken as a posed to adversarial approach.</p>
<h4>Keep pace with emerging security technologies</h4>
<p>Above we mentioned that each year brings an evolution of new threats, this is largely due to the emergence of new technologies, such as Web 2.0 and Internet applications. For this reason, existing skill sets often fall behind the evolution weakening the capabilities to stay on par with security threats. Annual security training ensures that employees are trained on security technologies that work to make sure there is no unexpectedly unprotected product. Statistics from the <a href="http://www.cert.org/vulnerability-analysis/publications/index.cfm">United States Computer Emergency Response Team</a> (CERT) show a rapid progression in total software vulnerabilities catalogued, hovering at about 7,000–8,000 per year during 2006 through 2008, up from about 1,100 in 2000.</p>
<h4>Deepen stakeholder security specialized knowledge</h4>
<p>Not only does annual security training ensure that employees are keeping pace with emergence of new threats, technology and security technologies, the education also facilitates a deeper understanding of software security allowing for further mitigation of security vulnerabilities. An employee is able to react appropriately when situations arise that are outside training. Furthermore, through training those employees that are excited by security can serve as mentors for others helping in secure code development or use of a specific code review tool.</p>
<h4>Organizational emergence of security first culture</h4>
<p>When an organization elects to focus on providing annual security training to its employees, overtime a security first culture naturally emerges permeating from executive directors all the way down to customer service representatives. An annual security training tailored to specific positions in the company facilitates this security first culture. So as you can see, security training does not begin and stop with software development, it encompasses the whole organization.</p>
<h4>Future return from security trained workforce</h4>
<p>A security trained workforce ensures that software vulnerabilities are mitigated overtime. It is well documented that the cost savings of finding and fixing vulnerabilities very early in the development cycle is significant - we cannot overlook this fact. We have to note, however, that there is no parallel correlation between software vulnerabilities and material loss, but with an emergence of new technologies the best way to ensure a reduction of vulnerabilities is by a security trained workforce.</p></p>
  			<a href="blog/2017/sdlc-process-comparison.html"><h1>Software Development Life Cycle (SDLC) Process Comparison</h1></a>
  			<p>14 January 2017</p>
  			<p><p>This article allows me to demonstrate my current understanding of the various software development life-cycles. I will be selecting two traditional Software Engineering Phases and compare and contrast each of them focusing on: How they differ? How they are similar? And define one advantage and one disadvantage for each SDLC process.</p>
<p>Software Development Life Cycle (SDLC) is a well-defined, structured sequence of stages in software engineering to develop an intended software product. SDLC provides as series of steps to be followed to design and develop a software product efficiently. </p>
<p>These steps include:</p>
<ol>
  <li>
  <p>
  <p><strong>Communication</strong></p>
  <blockquote>
    <blockquote>
      <p>This is the step that a user (customer) approaches a software developer or software company requesting for a desired software product. The user submits is desired software product in a document explaining how he/she wants it to function etc.…</p>
    </blockquote>
  </blockquote></p></li>
  <li>
  <p><strong>Requirement Gathering</strong></p>
  <blockquote>
    <blockquote>
      <p>From now onwards the software developer or software company takes over. A brainstorming process takes place. Each stakeholder of the product is interviewed to learn as much as possible about the requirements of the product. Questionnaires are handed out among others. The objective in this phase is to gather as much information as possible.</p>
    </blockquote>
  </blockquote></li>
  <li>
  <p><strong>Feasibility Study</strong></p>
  <blockquote>
    <blockquote>
      <p>After gathering required information from end users, the software developer(s) or software company analyzes whether a software can be made that address all required requirements. And if such a software can be made; are algorithms available? Is the technology feasible? How many developers are needed? Etc.</p>
    </blockquote>
  </blockquote></li>
  <li>
  <p><strong>System Analysis</strong></p>
  <blockquote>
    <blockquote>
      <p>At this stage, developers decide how they are to execute the project. They understand the product’s limitations, the system’s related potential problems identifying and addressing the impact of project on organization and people using software.</p>
    </blockquote>
  </blockquote></li>
  <li>
  <p><strong>Software Design</strong></p>
  <blockquote>
    <blockquote>
      <p>This step brings down gathered requirements and system analysis and design the software product.</p>
    </blockquote>
  </blockquote></li>
  <li>
  <p><strong>Coding</strong></p>
  <blockquote>
    <blockquote>
      <p>The implementation of software design starts in terms of writing program code in a suitable programming language.</p>
    </blockquote>
  </blockquote></li>
  <li>
  <p><strong>Testing</strong></p>
  <blockquote>
    <blockquote>
      <p>Software testing is done while coding by the developers and thorough testing is conducted by testing experts at various levels of code such as module testing, program testing, product testing, in-house testing and testing the product at user’s end.</p>
    </blockquote>
  </blockquote></li>
  <li>
  <p><strong>Integration</strong></p>
  <blockquote>
    <blockquote>
      <p>Software may need to be integrated with the libraries, databases and other program(s). This stage of SDLC is involved in the integration of software with outer world entities.</p>
    </blockquote>
  </blockquote></li>
</ol>
<p><strong>Waterfall Model</strong></p>
<p>Waterfall model is a sequential model. Software development is divided into separate phases and each phase is dependent on the success of the previous phase. The output of the one phase is the input of the other, so it is mandatory for the first phase to be completed before moving on to the next phase. The model assumes that everything produced in the previous step has no issues whatsoever because the model does not allow to go back and undo or redo our actions. In short, the development of one phase starts only when the previous phase is complete.</p>
<p><strong>Iterative Model</strong></p>
<p>Iterative model allows software developers to receive quick feedback at every stage of the development process. To give a simple illustration on how the model works; let’s say we are developing a small feature on our product, once we finish that feature we immediately test it to analyze how it functions, then using results gathered the test we go back to designing the feature making improvements. From there we continue coding and maybe expanding the feature. The process repeats until a large-scale software product is produced. As you can see, this model leads the software development process in iterations.</p>
<p><strong>Similarities between waterfall model and iterative model:</strong></p>
<p>In all fairness, there are few similarities between waterfall model and iterative model. One similarly that comes to mind is the ease at which both models can be implemented. Waterfall model being systematic by nature requiring that an output of the one phase is the input of the other - first phase to be completed before moving on to the next phase. Iterative model is cyclical – design, code, test and verify.</p>
<p><strong>Differences between waterfall model and iterative model:</strong></p>
<p>One of the most prominent differences between waterfall model and iterative model is the framework for software development process. As outlined above, waterfall model declares that the first step must be completed before moving onto the next step. Going further, it also assumes that everything produced in the previous step has no issues whatsoever and so it does not allow you to undo or redo actions. The waterfall model goes against the core structure of iterative model, in that unlike waterfall model, iterative model is designed to provide constant feedback by way of constant testing, evaluating, designing, verifying and repeating the whole process.</p>
<p><strong>One advantage for waterfall:</strong></p>
<p>The waterfall model is simple and easy to understand and use because stages are clearly defined and done one at a time. As a result, it is easy to make a prediction regarding the size, cost, and timeline of the project, as well as knowing how the finished product will turn out at the end of development. This model is great for small projects.</p>
<p><strong>One advantage for Iterative:</strong></p>
<p>One key advantage for implementing iterative model for software development process is that it allows products to be built and improved step by step. As a result, defects are able to be detected in early stages due to quick reliable feedback. This model is perfect for technology start-ups.</p>
<p><strong>One disadvantage for waterfall model:</strong></p>
<p>As we briefly touched on earlier in the post, waterfall model assumes that everything produced in the previous step has no issues whatsoever because the model does not allow to go back and undo or redo our actions. The development of one phase starts only when the previous phase is complete which is a major disadvantage. In software development, without adequate testing and feedback from end users, the likelihood of undetected defects in the software is high. It becomes very costly and difficult to go back and fix changes in large programs.</p>
<p><strong>One disadvantage for iterative model:</strong></p>
<p>Iterative model allows for quick feedback, which means projects are ever changing. For instance, the end of project may not be known until the project is fully compete. This uncertainty could mean project budget costs are unknown, on top of that, attention to risk analysis is higher compared to other models.</p></p>
  			<a href="blog/2017/software-vulnerability-sql-injection.html"><h1>Software Vulnerability - SQL Injection</h1></a>
  			<p>08 January 2017</p>
  			<p><p>In this article I create a simple form to demonstrate insecure interaction between a java based component<br/>and the outside world explaining why the form poses as a vulnerability to the overall application.<br/>Finally, I show how to properly secure the application. </p>
<p>A simple Java application is created with a simple login form that retrieves username and password using<br/>two JTextFields and storing them into the Derby Database.</p>
<pre><code>import java.sql.*;
import javax.swing.*;
import java.awt.*;
import java.awt.event.*;


public class JavaAppInsecureSQL implements ActionListener {
    
    private static String dbURL = &quot;jdbc:derby://localhost:1527/derbyDB;create=true;&quot;;
    private static String tableName = &quot;appusers&quot;;
    // jdbc Connection
    private static Connection conn = null;
    private static Statement stmt = null;
    
    JPanel totalGUI = new JPanel();
    JPanel textPanel, panelForTextFields, completionPanel;
    JLabel titleLabel, usernameLabel, passwordLabel, userLabel, passLabel;
    JTextField usernameField, loginField;
    JButton loginButton;
    
    String usernameText;
    String passwordText;
    
    public JPanel createContentPane(){
        // create bottom panel as a base for pane content     
        totalGUI.setLayout(null);        
        titleLabel = new JLabel(&quot;Login Screen&quot;);
        titleLabel.setLocation(0,0);
        titleLabel.setSize(290, 30);
        titleLabel.setHorizontalAlignment(0);
        totalGUI.add(titleLabel);
        
        // Creation of a Panel to contain the JLabels
        textPanel = new JPanel();
        textPanel.setLayout(null);
        textPanel.setLocation(10, 35);
        textPanel.setSize(70, 80);
        totalGUI.add(textPanel);

         // Username Label
        usernameLabel = new JLabel(&quot;Username&quot;);
        usernameLabel.setLocation(0, 0);
        usernameLabel.setSize(70, 40);
        usernameLabel.setHorizontalAlignment(4);
        textPanel.add(usernameLabel);

        // Login Label
        passwordLabel = new JLabel(&quot;Password&quot;);
        passwordLabel.setLocation(0, 40);
        passwordLabel.setSize(70, 40);
        passwordLabel.setHorizontalAlignment(4);
        textPanel.add(passwordLabel);

        // TextFields Panel Container
        panelForTextFields = new JPanel();
        panelForTextFields.setLayout(null);
        panelForTextFields.setLocation(110, 40);
        panelForTextFields.setSize(100, 70);
        totalGUI.add(panelForTextFields);

        // Username Textfield
        usernameField = new JTextField(8);
        usernameField.setLocation(0, 0);
        usernameField.setSize(100, 30);
        panelForTextFields.add(usernameField);

        // Login Textfield
        loginField = new JTextField(8);
        loginField.setLocation(0, 40);
        loginField.setSize(100, 30);
        panelForTextFields.add(loginField);
        
        // Creation of a Panel to contain the completion JLabels
        completionPanel = new JPanel();
        completionPanel.setLayout(null);
        completionPanel.setLocation(240, 35);
        completionPanel.setSize(70, 80);
        totalGUI.add(completionPanel);

        // Username Label
        userLabel = new JLabel(&quot;Wrong&quot;);
        userLabel.setForeground(Color.red);
        userLabel.setLocation(0, 0);
        userLabel.setSize(70, 40);
        completionPanel.add(userLabel);

        // Login Label
        passLabel = new JLabel(&quot;Wrong&quot;);
        passLabel.setForeground(Color.red);
        passLabel.setLocation(0, 40);
        passLabel.setSize(70, 40);
        completionPanel.add(passLabel);

        // Button for Logging in
        loginButton = new JButton(&quot;Login&quot;);
        loginButton.setLocation(130, 120);
        loginButton.setSize(80, 30);
        loginButton.addActionListener(this);
        totalGUI.add(loginButton);

        totalGUI.setOpaque(true);    
        return totalGUI;  
    }
    
    public void actionPerformed(ActionEvent e) {

        if(e.getSource() == loginButton)
        {
            if(!(usernameField.getText().trim().isEmpty()))
            {
                usernameText = usernameField.getText().trim();
                userLabel.setForeground(Color.green);
                userLabel.setText(&quot;Correct!&quot;);
            }
            else
            {
                userLabel.setForeground(Color.red);
                userLabel.setText(&quot;Wrong!&quot;);
            }

            if(!(loginField.getText().trim().isEmpty()))
            {
                passwordText = loginField.getText().trim();
                passLabel.setForeground(Color.green);
                passLabel.setText(&quot;Correct!&quot;);
            }
            else
            {
                passLabel.setForeground(Color.red);
                passLabel.setText(&quot;Wrong!&quot;);
            }

            if((userLabel.getForeground() == Color.green) 
			&amp;&amp; (passLabel.getForeground() == Color.green))
            {
                
                try{
                    titleLabel.setText(&quot;Storing into database....&quot;);
                    // insert user information into database
                    insertUserInfor(usernameText, passwordText);
                    
                    titleLabel.setText(&quot;Information stored!&quot;);
                }
                catch(Exception ex){
                    ex.getStackTrace();
                }finally{
                    loginButton.setEnabled(false);
                    // shutdown database connections
                    shutdown();
                }
                
            }
        }
    }
    
    private static void createAndShowGUI() {

        JFrame.setDefaultLookAndFeelDecorated(true);
        JFrame frame = new JFrame(&quot; Insecure SQL Java App &quot;);

        JavaAppInsecureSQL demo = new JavaAppInsecureSQL();
        frame.setContentPane(demo.createContentPane());
        
        frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);
        frame.setSize(310, 200);
        frame.setVisible(true);
    }
   
    public static void main(String[] args){
     
        //Event-dispatching thread:
        //creating and showing this application&#39;s GUI.
        SwingUtilities.invokeLater(new Runnable() {
            public void run() {
                createAndShowGUI();
            }
        });
        
    }
    
    private static void createConnection()
    {
        try
        {
            Class.forName(&quot;org.apache.derby.jdbc.ClientDriver&quot;).newInstance();
            //Get a connection
            conn = DriverManager.getConnection(dbURL); 
            
        }
        catch (ClassNotFoundException | InstantiationException | IllegalAccessException | SQLException except)
        {
            except.printStackTrace();
        }
        
    }
    
    private static void insertUserInfor(String userName, String userPass)
    {
        try
        {
            createConnection();
            stmt = conn.createStatement();
            stmt.execute(&quot;insert into &quot; + tableName + &quot; values (&#39;&quot; +
                    userName + &quot;&#39;, &#39;&quot; + userPass + &quot;&#39;)&quot;);
            
            stmt.close();
        }
        catch (SQLException sqlExcept)
        {
            sqlExcept.printStackTrace();
        }
    }
    
   
    private static void shutdown()
    {
        try
        {
            if (stmt != null)
            {
                stmt.close();
            }
            if (conn != null)
            {
                DriverManager.getConnection(dbURL + &quot;;shutdown=true&quot;);
                conn.close();
            }           
        }
        catch (SQLException sqlExcept)
        {
            sqlExcept.getStackTrace();
        }

    }
}
</code></pre>
<p>Once login button is pressed, the username and password is sent to be stored in the database.</p>
<p><strong>Note:</strong> The simple login application does not take into account other software vulnerabilities.<br/>We’re only demonstrating SQL Injection vulnerability. </p>
<p>The application works great, but when we take a look under the hood we find that this application is vulnerable<br/>to SQL Injection attacks because SQL statements are not prepared and are dynamically storing data directly into<br/>the database. </p>
<h3>Insecure Code</h3>
<hr/>
<pre><code> private static void insertUserInfor(String userName, String userPass)
    {
        try
        {
            createConnection();
            stmt = conn.createStatement();
            stmt.execute(&quot;insert into &quot; + tableName + &quot; values (&#39;&quot; +
                    userName + &quot;&#39;, &#39;&quot; + userPass + &quot;&#39;)&quot;);
            
            stmt.close();
        }
        catch (SQLException sqlExcept)
        {
            sqlExcept.printStackTrace();
        }
    }
</code></pre>
<p>SQL Injection attacks are the most prevent attacks to an application and inflicts the most damage exposing<br/>sensitive data. Injection attacks attempt to break into application databases by injecting malicious code,<br/>oftentimes in a form of SQL statements. They are often injected through form fields similar to the small<br/>application I created, but are also injected through uploads, 3rd party APIs, configuration files, input files etc. </p>
<h3>Secured Code</h3>
<hr/>
<p>The code snippet above shows the application retrieving username and password directly placing it into the SQL<br/>statement without validating or sanitizing the data. Essentially, the developer trusts the user not to<br/>inject malicious code. The user should never be trusted. Below I demonstrate how to properly prepare SQL statements<br/>in java. </p>
<pre><code>private static void insertUserInfor(String userName, String userPass)
    {
        try
        { 
            // establish connection
            createConnection();
            String qTxt = &quot;INSERT INTO &quot; + tableName + &quot;VALUES (?,?)&quot;;
            prepStmt = conn.prepareStatement(qTxt);
            prepStmt.setString(1, userName);
            prepStmt.setString(1, userPass);
            
            prepStmt.close();
        }
        catch (SQLException sqlExcept)
        {
            sqlExcept.printStackTrace();
        }
    }
</code></pre>
<p>When SQL statements are prepared information received from the user is placed in a prepared statement and not directly<br/>into the SQL query, thus mitigating dynamic queries. </p>
<p>In this demonstration, I have alluded to mention another measure to take in order to mitigate SQL Injection attacks,<br/>which is to validate and sanitize data retrieved from the user. As we’ve mentioned, the application cannot trust data<br/>from the outside world. Information must be validated for content, length, format, and other factors before use. </p></p>
  			<a href="blog/2016/db-comparison-oracle-vs-dynamo.html"><h1>Database Comparison: Oracle 12c vs. Amazon DynamoDB</h1></a>
  			<p>17 December 2016</p>
  			<p><p>You successfully applied and landed one of your biggest contracts that expects you to design, manage and scale a database for a medium size manufacturing and distribution company. Business requirements state that the database must be hosted in the cloud. After conducting research, you’ve landed on two of the most popular databases Amazon DynamoDB and Oracle 12c. </p>
<p>Dynamo is Amazon’s managed NoSQL service known for its strong consistency and predictable performance. Its design feature is quite different from Oracle 12c, a Relational Database. Instead of the relational model, Dynamo uses alternate models for data management, such as key-value pairs or document storage. Comparisons of health, storage, and network connectivity between Oracle and Dynamo was a challenge since Dynamo is a managed service, meaning that Amazon Web Services provisions and running of infrastructure are handled for users. </p>
<p>On the other hand, Oracle 12c is a version of the Oracle Database which can be referred to as an Oracle Relational Database Management System, an object-relational database management system. Oracle 12c is a cloud enabled database, the ‘c’ on the 12 indicates ‘cloud’. The database features include a multi-tenant option that help users bring together databases into a private or public clouds with the added capacity to share the same hardware, platform, and network making it ideal for the distribution side of the company. </p>
<p>Regardless of which database should be implemented for the business, whether that is Dynamo or Oracle 12c, a database system must have scalable and robust mechanisms for its basic functions which include consistent storing, modifying, and retrieving data while efficiently handling failure detection, failure recovery, overloading handling, system monitoring among others. I find that discussing every detail of each mechanism to make a comparison between the two databases will eat up a lot of paper, and frankly would be missing the mark. Instead the discussion will focus on the three core system features used in Oracle 12c and Dynamo and compare the differences in the conclusion.</p>
<p><strong>Physical Storage Structures</strong></p>
<p><em>Oracle</em></p>
<p>Unlike NoSQL ecosystems, relational databases such as Oracle 12c have to allocate space for tablespace which are physically stored in data files. Each tablespace consists of one or more data files which mold to the host’s operating system where the database is running. The allocated disk space is formatted but contains no user data, so as the data grows space is used to allocate extents for the segment. Another distinction is that in Oracle 12c every data file is either online or offline. The administrator has ability to determine when data files are available. </p>
<p>Another note is that Oracle 12c leans on control files that serve multiple important roles in the overall functionality of managed data files. They contain data files, online redo files, and others needed to open the database. Structural changes to the database are also monitored and tracked. Metadata must be accessible when the database is not open, so it is the control file’s job to provide checkpoints where instance recovery would be required to begin.</p>
<p>To protect against data loss, Oracle 12c maintains online redo log files so that data not yet written to data files is able to be retrieved after an instance failure. It is able to do this because server processes write every transaction synchronously to the redo log buffer. Online redo log always contains the undo data for permanent objects. Unlike Dynamo, with Oracle 12c the administrator is able to configure the database to store all undo data.</p>
<p><em>Dynamo</em></p>
<p>Dynamo fundamentally differs from Oracle storage system in terms of the aim of its requirements. Dynamo was created with the mindset that applications using it will always be “writeable”, and to achieve this, data store mechanisms were made to always update regardless of server failures or concurrent writes. This is a common requirement for many NoSQL ecosystems including of course Amazon applications, bringing us to another distinction. Dynamo is built for an infrastructure within a single domain where all nodes are assumed to be trusted. </p>
<p>Two of the requirements that make Dynamo unique is its ability to scale incrementally and the use of vector clocks. To allow for this mechanism of scaling incrementally, its storage structures dynamically partition data over a set of nodes in the system. In particular, Dynamo’s partitioning relies on consistent hashing to distribute the load across multiple storage hosts which allows it to scale extremely fast at short amount of time. Dynamo uses vector clocks to capture events between different versions of the same object. A vector clock is essentially a list of node pairs and each clock is associated with version of every object.</p>
<p><strong>Logical Storage Structures</strong> </p>
<p><em>Oracle</em></p>
<p>Data in Oracle is stored in data block, extent, segment and tablespace; however, some of these storage hierarchy can be found inside one another. For example, a segment is a set of allocated specific database table and a table is a storage unit that contains one or more segments. Each segment belongs to one tablespace.</p>
<p>As we’ll find later, Dynamo’s partition settings are dynamically increased depending on the throughput. Oracle has a similar mechanism for keeping track and allocating additional storage in tablespace or retracting storage when an object no longer requires it. To achieve this, Oracle uses bitmaps in the tablespace which are aside for a bitmap. Automatic Segment Space Management method uses these bitmaps to manage space in a tablespace.</p>
<p>Each Oracle user is assigned a default permanent tablespace. Tablespaces control disk space allocation of data, control tablespace online and offline, perform backup and recovery and export and import application data. Temporary tablespace is also deployed when a permanent tablespace is operational, however its data lasts only for the duration of a session. They serve to improve the efficiency of space management operation.</p>
<p><em>Dynamo</em></p>
<p>Dynamo is a fully managed document database service running in the AWS cloud that provides very fast and predictable performance. The database is optimized to retrieve and store semi-structured data as documents, formatted in JSON or XML. </p>
<p>Data in Dynamo is stored in partitions which are basically an allocated storage for a table, backed by solid-state drives and automatic replication across multiple available zones in AWS region. When a table is being created the database automatically allocates enough partitions so that the table can handle user set provisioned throughput requirements. And since Dynamo is designed to scale super-fast, increases in table’s provisioned throughput settings beyond what currently exists at a moment’s notice can allocate additional partitions.</p>
<p>Moving forward with our discussion on logical storage structures, it is important to understand how data is handled under Dynamo’s key/value interface. Tables usually have a partition key only or a partition key and sort key. Dynamo handles the two slightly differently to optimize efficiency. Under a partition key only table, the key has to be referenced when writing and reading items. A table with partition key and sort key similar to partition key, only now items are grouped and ordered by sort key value.</p>
<p><strong>Data processing</strong> </p>
<p><em>Oracle</em></p>
<p>Oracle being a Relational Database Management System adheres to Structured Query Language which provides the interface. All operations of the data in Oracle are performed using SQL statements. For instance, SQL statement could be used to create tables, query, and modify data in tables. A procedural extension named PL/SQL embedded with Oracle database allows developers to use all Oracle Database SQL statements, functions and data types. What is unique about this procedural extension is its ability to provide control to the flow of SQL program, variables and deployment of error-handling procedures. </p>
<p><em>Dynamo</em></p>
<p>As noted earlier, Dynamo relies on provisioned throughput model to process data. A user is able specify read and writes via documents, such as JSON, XML declaring number of input operations that a table is expected to achieve. A user is also able to declare consistency characteristics for each read request within an application. The number of input operations can be determined by Item size, expected read and write request rates, has local or global secondary indexes etc.</p>
<p>Oracle 12c has a domain-specific language to query data, however Dynamo provides access with a simple application programming interface to create, read, update and delete data. Dynamo also has batch operations for reading and writing multiple items/rows across multiple tables. Another feature available is an atomic item and attribute operation, which basically allows for updating, adding, deleting and item only if a certain value is present or not present.</p>
<p>Dynamo’s impressive capabilities of taking in large amounts of data at a given notice means that it should also be able to read millions of data efficiently. To achieve this, Dynamo and many NoSQL databases support scan capabilities to address large-scale analytical processing. Dynamo’s Query API, filters and parallel scanning could be applied to narrow down result set.</p>
<p><strong>Metrics Comparison</strong></p>
<p><strong>Data model</strong></p>
<blockquote>
  <p>Oracle 12c</p>
  <blockquote>
    <p>Oracle’s relational structure organizes data into tables, which consist of rows and columns. The schema defines the tables, columns, indexes, relationships between tables, and other database elements.</p>
  </blockquote>
  <p>Amazon DynamoDB</p>
  <blockquote>
    <p>A partition key is used to retrieve values, column sets, or semi-structured JSON, XML or other documents containing related item attributes.</p>
  </blockquote>
</blockquote>
<hr/>
<p><strong>Performance</strong></p>
<blockquote>
  <p>Oracle 12c</p>
  <blockquote>
    <p>Performance is generally dependent on the disk subsystem. Optimization of queries, indexes, and table structure is required to achieve peak performance.</p>
  </blockquote>
  <p>Amazon DynamoDB</p>
  <blockquote>
    <p>The performance is generally a function of the underlying hardware cluster size, network latency, and the calling application.</p>
  </blockquote>
</blockquote>
<hr/>
<p><strong>Scale</strong></p>
<blockquote>
  <p>Oracle 12c</p>
  <blockquote>
    <p>Oracle’s structure makeup makes it easiest to scale up with faster hardware.</p>
  </blockquote>
  <p>Amazon DynamoDB</p>
  <blockquote>
    <p>Dynamo was designed with the purpose of scaling out using distributed clusters of low-cost hardware to increase throughput without increasing latency.</p>
  </blockquote>
</blockquote>
<hr/>
<p><strong>APIs</strong></p>
<blockquote>
  <p>Oracle 12c</p>
  <blockquote>
    <p>Structured Query Language (SQL) is used to store and retrieve data requests. Queries are parsed and executed by relational database management systems (RDBMS).</p>
  </blockquote>
  <p>Amazon DynamoDB</p>
  <blockquote>
    <p>It is easy to retrieve and store data structures with object-based APIs. Partition keys let applications look up key-value pairs, column sets, or semi-structured documents.</p>
  </blockquote>
</blockquote>
<hr/>
<p><strong>Data Storage</strong></p>
<blockquote>
  <p>Oracle 12c</p>
  <blockquote>
    <p>Partitions. </p>
  </blockquote>
  <p>Amazon DynamoDB</p>
  <blockquote>
    <p>Automatic Segment Space Management (ASSM) is used in conjunction with bitmaps.</p>
  </blockquote>
</blockquote>
<hr/>
<p><strong>Conclusion</strong></p>
<p>Amazon Dynamo and Oracle 12c are all excellent databases because they are capable of scaling extremely fast in a short amount of time. Deciding on what database to implement for a business setting ultimately depends on the type of data you’ll be storing, the volume of data, among others. Each database has its strength and weaknesses. While conducting research, I found that a user willing to be hands on might consider working with Oracle 12c. With Oracle, you have to provide your own hardware, for example to allocate disk space used to create room for the segments. You also have control over whether the database is online or offline, determining when data files are available. Dynamo removes you from having to think about how to set up the infrastructure because the database’s ecosystem is handled by Amazon Web Services.</p>
<p>Each database handles instance failure different as well, I found that Oracle automatically maintains processes to write every transaction synchronously to the redo log buffer so that data not yet written to data files can be retrieved. Dynamo was designed with the expectation that failures are going to occur, so the database is constantly anticipating these anomalies, as a result, data store mechanisms were made to also update regardless of server failure. In this sense, each database handles these basic but critical functions. So in a sense both databases are similar in that they have the capabilities to handle instance failure. </p>
<p>Another similarity to point out is that both databases are capable of scaling extremely fast in a short amount of time, though each accomplishes this in its own unique way. We know that data is stored in partitions in Dynamo, so when a large amount of data is stored partition settings dynamically increase. And for Oracle, an Automatic Segment Space Management (ASSM) is used in conjunction with bitmaps to manage space in tablespace. In a sense, ASSM functions similar to partition settings in that storage is able to be automatically fluctuate to accommodate incoming flows of data.</p>
<p>In conclusion, determining which database to use boils down to your business requirements and expectations of how data should be stored, modified or gathered. I would be remised if I did not end the discussion by mentioning one obvious distinction, which is that Oracle is a relational database management system and adheres to Structured Query Language. On the other hand, as we’ve touch on quite a bit is that Dynamo a NoSQL database relying on a provisioned throughput model to process data via documents, such as JSON and XML.</p></p>
  			<a href="blog/2016/Optimistic-view-of-2016.html"><h1>The optimistic view of 2016</h1></a>
  			<p>04 January 2016</p>
  			<p><p>At this time each year I take a moment to reflect on the year that was. The year 2015 began with me knowing that I was embarking on the next phase in my life given that I had just graduated from college in December 2014. I had somewhat of an idea how the year would turn out; for example, I had secured an internship with MenEngage so I knew I’ll be working in D.C but didn’t quite know how it would pan-out, I wasn’t totally jumping for joy about the opportunity simply glad that I wouldn’t be home searching for jobs. Also I knew that I would be visiting Africa for a period of time and that it would be the first time visiting the continent in roughly 13 years. My visit to Africa was what I looked forward to the most starting the year because I somehow knew it would change the course of my life (my thinking) and indeed my life was forever changed. This brought with it a lot of turbulence both mentally and professionally. The trip allowed me to rethink how I thought about careers, allowed me to look deep inside myself to determine truly what I wanted to do with my life - understanding what path in life would help me reach my burning desires. So as you can imagine, there was a lot uncertainty and confusion during this time. I beat myself up inside for not foreseeing and actually valuing my education before getting to this point, and I vow to never take life and opportunities for granted.</p>
<p>The New Year has approached in quick fashion bringing with it an abundance of optimism. There is no doubt that 2016 is going to be special. Special in terms of not only will it be my second year in the real world, but this year I’ll consume more information that I have consumed last year and the year before. For starters, I’ll continue with course work at UMUC, in fact, in total I’ll be taking 7 courses in Software Development and Security. On top of that, during the summer I’ll aim to secure an internship to supplement my education and gain real work experience and make connections in the software security field.</p>
<p>Secondly, in 2016, I’ll continue assisting Mr. Augustine Guma with is Start-Up Gumax International. This year Gumax International is expended to open a brand new restaurant in Woodbridge called Gumax Spicy Pies which is projected to generate a lot of revenue for the company. Before 2015 ended customers were placing in orders for the products so all these positive signs imply that the restaurant will be welcomingly busy. Another thing to look forward to is that Gumax International was picked as one of the vendors at the Super Bowl in San Francisco this coming February. I hope Guma picks me to attend such a massive event. Lastly, I’ll experience first hand how it’s like to work as a staff accountant during tax season. During this period my accountancy skills will truly be enhance expanding my brain further.</p>
<p>I cannot write a first blog without mentioning the people in my life that make my life happen and enjoyable. There is one thing that I’ve learned in this world no one no matter how successful someone is no one goes through life by themselves. Each year as life happens people enter and leave your life some enhance your life making you a better person emotionally, professionally or economically, and some enter your life to only pull you back. On August 16th 2015, I was able to have the girl of my dreams enter my life. She not only makes my heart sing sounds of joy each time I see her, but she stimulates my brain and my thinking each time we talk. I look forward sharing my journey with her this year. My family also plays a massive role; they are always supportive, always patent with me and are always looking out for my best interest even when I cannot see it at the time. I love all of them and cannot wait to make them proud someday.</p></p>
	
	<hr />
	
	<p>Older posts are available in the <a href="archive.html">archive</a>.</p>

		</div>
		<div id="push"></div>
    </div>
    
    <div id="footer">
      <div class="container">
        <p class="muted credit">&copy; 2017 | Mixed with <a href="http://getbootstrap.com/">Bootstrap v3.1.1</a> | Baked with <a href="http://jbake.org">JBake v2.5.0</a></p>
      </div>
    </div>
    
    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="js/jquery-1.11.1.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/prettify.js"></script>
    
  </body>
</html>

